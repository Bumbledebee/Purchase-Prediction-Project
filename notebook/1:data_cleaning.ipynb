{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the data cleaning is to have final file that can be used for exploraty data analysis.\n",
    "Steps:\n",
    " - take care of duplicated rows and empty values\n",
    " - convert event_type == 'purchase' into a feature for the last view before the purchase\n",
    " - convert event_type == 'cart' into two features before and after a view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils import helper_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-24 11:57:06 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>1996170</td>\n",
       "      <td>2144415922528452715</td>\n",
       "      <td>electronics.telephone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>1515915625519388267</td>\n",
       "      <td>LJuJVLEjPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-24 11:57:26 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>139905</td>\n",
       "      <td>2144415926932472027</td>\n",
       "      <td>computers.components.cooler</td>\n",
       "      <td>zalman</td>\n",
       "      <td>17.16</td>\n",
       "      <td>1515915625519380411</td>\n",
       "      <td>tdicluNnRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-24 11:57:27 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>215454</td>\n",
       "      <td>2144415927158964449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1515915625513238515</td>\n",
       "      <td>4TMArHtXQy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-24 11:57:33 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>635807</td>\n",
       "      <td>2144415923107266682</td>\n",
       "      <td>computers.peripherals.printer</td>\n",
       "      <td>pantum</td>\n",
       "      <td>113.81</td>\n",
       "      <td>1515915625519014356</td>\n",
       "      <td>aGFYrNgC08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-24 11:57:36 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>3658723</td>\n",
       "      <td>2144415921169498184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cameronsino</td>\n",
       "      <td>15.87</td>\n",
       "      <td>1515915625510743344</td>\n",
       "      <td>aa4mmk0kwQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2020-09-24 11:57:06 UTC       view     1996170  2144415922528452715   \n",
       "1  2020-09-24 11:57:26 UTC       view      139905  2144415926932472027   \n",
       "2  2020-09-24 11:57:27 UTC       view      215454  2144415927158964449   \n",
       "3  2020-09-24 11:57:33 UTC       view      635807  2144415923107266682   \n",
       "4  2020-09-24 11:57:36 UTC       view     3658723  2144415921169498184   \n",
       "\n",
       "                   category_code        brand   price              user_id  \\\n",
       "0          electronics.telephone          NaN   31.90  1515915625519388267   \n",
       "1    computers.components.cooler       zalman   17.16  1515915625519380411   \n",
       "2                            NaN          NaN    9.81  1515915625513238515   \n",
       "3  computers.peripherals.printer       pantum  113.81  1515915625519014356   \n",
       "4                            NaN  cameronsino   15.87  1515915625510743344   \n",
       "\n",
       "  user_session  \n",
       "0   LJuJVLEjPT  \n",
       "1   tdicluNnRY  \n",
       "2   4TMArHtXQy  \n",
       "3   aGFYrNgC08  \n",
       "4   aa4mmk0kwQ  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '../data/events.csv' \n",
    "# The file is not shown on github, buy you may check the sample 'data/sample_events.csv'\n",
    "df = pd.read_csv(filepath) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 885129 entries, 0 to 885128\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   event_time     885129 non-null  object \n",
      " 1   event_type     885129 non-null  object \n",
      " 2   product_id     885129 non-null  int64  \n",
      " 3   category_id    885129 non-null  int64  \n",
      " 4   category_code  648910 non-null  object \n",
      " 5   brand          672765 non-null  object \n",
      " 6   price          885129 non-null  float64\n",
      " 7   user_id        885129 non-null  int64  \n",
      " 8   user_session   884964 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 60.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # columns, non-null counts, dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885129, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 655 duplicate rows, 448748 empty values and 0 empty spaces\n",
      "\n",
      "Duplicate Rows:\n",
      "0.07% of duplicated rows. View some of them below:\n",
      "                     event_time event_type  product_id          category_id  \\\n",
      "412267  2020-12-08 13:23:00 UTC   purchase      886022  2144415921001726020   \n",
      "260767  2020-11-11 17:43:27 UTC       view     3828462  2144415924684325027   \n",
      "364848  2020-11-28 09:48:51 UTC       view     4099764  2144415923207929981   \n",
      "\n",
      "                      category_code        brand   price              user_id  \\\n",
      "412267                          NaN      samsung   26.57  1515915625555872974   \n",
      "260767  electronics.audio.headphone  steelseries  201.33  1515915625538273918   \n",
      "364848      auto.accessories.player      pioneer  126.68  1515915625545724737   \n",
      "\n",
      "       user_session  \n",
      "412267   oFI06mHVxf  \n",
      "260767   5kgQcCdG4x  \n",
      "364848   isQlu5xBhW  \n",
      "\n",
      "NaN Rows:\n",
      "26.69% of NaNs in the category_code column\n",
      "23.99% of NaNs in the brand column\n",
      "0.02% of NaNs in the user_session column\n"
     ]
    }
   ],
   "source": [
    "hf.check_data(df) #custom function to check for duplicate, nulls and empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_time       845041\n",
       "event_type            3\n",
       "product_id        53453\n",
       "category_id         718\n",
       "category_code       107\n",
       "brand               999\n",
       "price             12422\n",
       "user_id          407283\n",
       "user_session     490398\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values per column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "view        793748\n",
       "cart         54035\n",
       "purchase     37346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the three unique event types of this dataframe\n",
    "df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the event_time to a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'event_time' column to datetime format\n",
    "# This is important for time series analysis and any time-based filtering\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a data sample for Github\n",
    "We would not like to reveal the original dataset to the reader, but only a sample to get an idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 100 rows into a new DataFrame\n",
    "df_sample = df.sample(100, random_state=1)\n",
    "# Convert the DataFrame to a CSV file\n",
    "df_sample.to_csv('../data/sample_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the duplications\n",
    "ALthough only 0.07% of the rows are duplicated, we want to take a closer look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07% of duplicated rows.\n"
     ]
    }
   ],
   "source": [
    "perc = str(round(df.duplicated().sum() / len(df) * 100, 2))\n",
    "print(f\"{perc}% of duplicated rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "view        1272\n",
       "cart           6\n",
       "purchase       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding all duplicated rows including the original row to a new DataFrame\n",
    "df_duplicates = df[df.duplicated(keep=False)]\n",
    "# Adding those duplicated rows to a new CSV file\n",
    "df_duplicates.to_csv('../data/cleaning/duplicates.csv', index=False)\n",
    "# checking for which event type this duplication is happening\n",
    "df_duplicates['event_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-24 13:51:07+00:00\n",
      "2021-02-28 14:18:02+00:00\n",
      "user_id\n",
      "1515915625530338453    14\n",
      "1515915625598503848    13\n",
      "1515915625551553663    12\n",
      "1515915625561515907    12\n",
      "1515915625512176731     8\n",
      "1515915625595650588     8\n",
      "1515915625596017017     7\n",
      "1515915625548733800     6\n",
      "1515915625540086964     6\n",
      "1515915625545471734     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking for which time frame the duplication is happening\n",
    "print(df_duplicates['event_time'].min()), print(df_duplicates['event_time'].max())\n",
    "# checking for which user id this duplication is happening\n",
    "print(df_duplicates['user_id'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment of duplicated rows:\n",
    "As it only happens < 1% of the times it seems not to be a normal process but rather a glitch in the system. We would need to ask the developers what it means to get the same event twice. If exactly the same event with all same columns has been recorded twice although it just happened once, then we can safely remove the duplication as there is no information lost.\n",
    "We are going with this assumption and thus removing the duplicated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "# Check if duplicates are removed\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Rows:\n",
      "26.69% of NaNs in the category_code column\n",
      "24.0% of NaNs in the brand column\n",
      "0.02% of NaNs in the user_session column\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of NaN values per column\n",
    "# This is important for understanding the completeness of the data\n",
    "# and deciding how to handle missing values\n",
    "nan_values = df.isna().sum()\n",
    "print(\"NaN Rows:\")\n",
    "for x in nan_values[nan_values > 0].index:\n",
    "    perc = str(round(df[x].isna().sum() / len(df) * 100, 2))\n",
    "    print(f\"{perc}% of NaNs in the {x} column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-24 11:57:06+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>1996170</td>\n",
       "      <td>2144415922528452715</td>\n",
       "      <td>electronics.telephone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>1515915625519388267</td>\n",
       "      <td>LJuJVLEjPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-24 11:57:27+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>215454</td>\n",
       "      <td>2144415927158964449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1515915625513238515</td>\n",
       "      <td>4TMArHtXQy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-24 11:57:36+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>3658723</td>\n",
       "      <td>2144415921169498184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cameronsino</td>\n",
       "      <td>15.87</td>\n",
       "      <td>1515915625510743344</td>\n",
       "      <td>aa4mmk0kwQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-24 11:58:23+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>3791349</td>\n",
       "      <td>2144415935086199225</td>\n",
       "      <td>computers.desktop</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.41</td>\n",
       "      <td>1515915625519388877</td>\n",
       "      <td>J1t6sIYXiV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-24 11:58:25+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>657859</td>\n",
       "      <td>2144415939431498289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.17</td>\n",
       "      <td>1515915625519320570</td>\n",
       "      <td>HEl15U7JVy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 event_time event_type  product_id          category_id  \\\n",
       "0 2020-09-24 11:57:06+00:00       view     1996170  2144415922528452715   \n",
       "1 2020-09-24 11:57:27+00:00       view      215454  2144415927158964449   \n",
       "2 2020-09-24 11:57:36+00:00       view     3658723  2144415921169498184   \n",
       "3 2020-09-24 11:58:23+00:00       view     3791349  2144415935086199225   \n",
       "4 2020-09-24 11:58:25+00:00       view      657859  2144415939431498289   \n",
       "\n",
       "           category_code        brand   price              user_id  \\\n",
       "0  electronics.telephone          NaN   31.90  1515915625519388267   \n",
       "1                    NaN          NaN    9.81  1515915625513238515   \n",
       "2                    NaN  cameronsino   15.87  1515915625510743344   \n",
       "3      computers.desktop          NaN  215.41  1515915625519388877   \n",
       "4                    NaN          NaN   34.17  1515915625519320570   \n",
       "\n",
       "  user_session  \n",
       "0   LJuJVLEjPT  \n",
       "1   4TMArHtXQy  \n",
       "2   aa4mmk0kwQ  \n",
       "3   J1t6sIYXiV  \n",
       "4   HEl15U7JVy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify rows with any NaN values and write to a new dataframe\n",
    "df_nan = df[df.isna().any(axis=1)].reset_index(drop=True)\n",
    "df_nan.to_csv('../data/cleaning/nan_values_all.csv', index=False)\n",
    "df_nan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking empty brand and category_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some product_ids have no brand or category code. The question is whether somewhere else in the dataframe the same product_id does have a brand name or category_code. For this reason, I create a unique dictionary with all product_ids and what brand or category code they map too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup dictionary for product_id to (brand, category_code)\n",
    "product_dict = {}\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for _, row in df_nan[['product_id', 'brand', 'category_code']].drop_duplicates().iterrows():\n",
    "    product_id = row['product_id']\n",
    "    brand = row['brand']\n",
    "    category_code = row['category_code']\n",
    "    \n",
    "    # Fill missing values if possible\n",
    "    if pd.isna(brand):\n",
    "        brand = df.loc[df['product_id'] == product_id, 'brand'].dropna().unique()\n",
    "        brand = brand[0] if len(brand) > 0 else None\n",
    "    if pd.isna(category_code):\n",
    "        category_code = df.loc[df['product_id'] == product_id, 'category_code'].dropna().unique()\n",
    "        category_code = category_code[0] if len(category_code) > 0 else None\n",
    "    \n",
    "    # Add to dictionary\n",
    "    product_dict[product_id] = {\"brand\" : brand , \"category_code\" : category_code}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I compare the dictionary with my df_nan dataframe (any row that has an empty value) to see if anything could be mapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is remapping needed for 'brand': No, Is remapping needed for 'category_code': No\n"
     ]
    }
   ],
   "source": [
    "unique_product_ids_with_none_brand_fromDict = len([product_id for product_id, details in product_dict.items() if details['brand'] is None])\n",
    "unique_product_ids_with_none_category_code_fromDict = len([product_id for product_id, details in product_dict.items() if details['category_code'] is None])\n",
    "unique_product_ids_with_none_brand_fromDFNAN = df_nan[df_nan['brand'].isna()].product_id.nunique()\n",
    "unique_product_ids_with_none_category_code_fromDFNAN = df_nan[df_nan['category_code'].isna()].product_id.nunique()\n",
    "\n",
    "print(\n",
    "    f\"Is remapping needed for 'brand': {'Yes' if unique_product_ids_with_none_brand_fromDict != unique_product_ids_with_none_brand_fromDFNAN else 'No'}, \"\n",
    "    f\"Is remapping needed for 'category_code': {'Yes' if unique_product_ids_with_none_category_code_fromDict != unique_product_ids_with_none_category_code_fromDFNAN else 'No'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As no mapping can be found, we can fill all empty values with \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'] = df['brand'].fillna('Unknown')\n",
    "df['category_code'] = df['category_code'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Rows:\n",
      "0.02% of NaNs in the user_session column\n"
     ]
    }
   ],
   "source": [
    "nan_values = df.isna().sum()\n",
    "print(\"NaN Rows:\")\n",
    "for x in nan_values[nan_values > 0].index:\n",
    "    perc = str(round(df[x].isna().sum() / len(df) * 100, 2))\n",
    "    print(f\"{perc}% of NaNs in the {x} column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the empty user sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows with any NaN values and write to a new dataframe\n",
    "df_nan_session = df[df.isna().any(axis=1)].reset_index(drop=True)\n",
    "df_nan_session.to_csv('../data/cleaning/nan_values_session.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1515915625598210358    4\n",
       "1515915625543219641    3\n",
       "1515915625605766062    3\n",
       "1515915625553241966    3\n",
       "1515915625598706843    3\n",
       "                      ..\n",
       "1515915625534728266    1\n",
       "1515915625534674543    1\n",
       "1515915625534584354    1\n",
       "1515915625534174318    1\n",
       "1515915625573421999    1\n",
       "Name: count, Length: 140, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan_session.user_id.value_counts() # checking which users have how many empty sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "view    156\n",
       "cart      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan_session.event_type.value_counts() # checking how many events have empty sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-24 23:47:04+00:00\n",
      "2021-02-18 11:28:16+00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for which time frame the empty sessions are happening\n",
    "print(df_nan_session['event_time'].min()), print(df_nan_session['event_time'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently empty session is not tied to one user, one event_type or timeframe. For this reason, deciding to fill up with \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_session'] = df['user_session'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the dataframe sequentially by user_id and product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['user_id', 'product_id', 'event_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midpoint: A sorted and cleaned dataframe is a good one to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/events_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparting Data for the last view before purchase analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a sanity check example dataset to validate the methods are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1515915625601579158    56\n",
       "1515915625591659523    49\n",
       "1515915625596534847    45\n",
       "1515915625604175669    43\n",
       "1515915625605054644    42\n",
       "1515915625599634258    39\n",
       "1515915625521745364    36\n",
       "1515915625603840072    33\n",
       "1515915625603113992    28\n",
       "1515915625540197343    24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['event_type'] == 'purchase'].user_id.value_counts().head(10) # grabbing a few users that had a purchase event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting thse users into a list for the sanity check\n",
    "user_ids_to_test = (1515915625601579158, 1515915625591659523, 1515915625596534847, 1515915625604175669, 1515915625605054644)\n",
    "\n",
    "# Creating a Test DataFrame with only those users from the list and saving to a csv file\n",
    "test_df = df[df['user_id'].isin(user_ids_to_test)]\n",
    "test_df = test_df.sort_values(by=['user_id', 'product_id', 'event_time'])\n",
    "test_df.to_csv('sanity_check/test_df.csv', index=False)\n",
    "\n",
    "# The code below performed on the whole dataframe has been sanity checked in notebooks/sanity_check/example.ipynb. \n",
    "# Feel free to check there the logic which is then applied to the whole dataframe below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the purchase event row into a feature of the previous view event\n",
    "We want every view before the purchase to be marked if it was the last view before purchase per user_id and product_id sequentially (in case the same user_id and product_id combinations buys the same product_id on multiple occassions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column initialized to 0\n",
    "df['last_view_before_purchase'] = 0\n",
    "\n",
    "# Iterate through the groups of 'user_id' and 'product_id'\n",
    "def mark_last_view_before_purchase(group):\n",
    "    purchase_indices = group.index[group['event_type'] == 'purchase'].tolist()\n",
    "    if not purchase_indices:\n",
    "        return group\n",
    "\n",
    "    for purchase_index in purchase_indices:\n",
    "        # Find the last 'view' before this 'purchase'\n",
    "        views_before_purchase = group[(group.index < purchase_index) & (group['event_type'] == 'view')]\n",
    "        if not views_before_purchase.empty:\n",
    "            last_view_index = views_before_purchase.index[-1]\n",
    "            group.at[last_view_index, 'last_view_before_purchase'] = 1\n",
    "\n",
    "    return group\n",
    "\n",
    "df = df.groupby(['user_id', 'product_id']).apply(mark_last_view_before_purchase)\n",
    "\n",
    "# Overwrite our final file\n",
    "df.to_csv('../data/events_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index levels: [None]\n"
     ]
    }
   ],
   "source": [
    "print(\"Current index levels:\", test_df.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the cart event row into a feature of the previous view event\n",
    "We want every view before the cart to be marked if it was the last view before cart per user_id and product_id sequentially "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column initialized to 0\n",
    "df['last_view_before_cart'] = 0\n",
    "\n",
    "# Function to mark the last view before a cart event\n",
    "def mark_last_view_before_cart(group):\n",
    "    cart_indices = group.index[group['event_type'] == 'cart'].tolist()\n",
    "    if not cart_indices:\n",
    "        return group\n",
    "\n",
    "    for cart_index in cart_indices:\n",
    "        # Find the last 'view' before this 'cart'\n",
    "        views_before_cart = group[(group.index < cart_index) & (group['event_type'] == 'view')]\n",
    "        if not views_before_cart.empty:\n",
    "            last_view_index = views_before_cart.index[-1]\n",
    "            group.at[last_view_index, 'last_view_before_cart'] = 1\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of user_id and product_id\n",
    "df = df.groupby(['user_id', 'product_id']).apply(mark_last_view_before_cart)\n",
    "\n",
    "# Overwrite our final file\n",
    "df.to_csv('../data/events_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['already_in_cart'] = 0\n",
    "\n",
    "# Function to mark views that follow a cart event without a purchase in between\n",
    "def mark_view_after_cart(group):\n",
    "    # Get indices of cart and view events\n",
    "    cart_indices = group.index[group['event_type'] == 'cart'].tolist()\n",
    "    view_indices = group.index[group['event_type'] == 'view'].tolist()\n",
    "    \n",
    "    # Iterate over each cart event index\n",
    "    for cart_index in cart_indices:\n",
    "        # Find the first view after the cart event\n",
    "        for view_index in view_indices:\n",
    "            if view_index > cart_index:\n",
    "                # Check if there is a purchase between the cart and the view\n",
    "                purchase_between = group.loc[cart_index + 1:view_index - 1]['event_type'].eq('purchase').any()\n",
    "                \n",
    "                # Only mark if there is no purchase event in between\n",
    "                if not purchase_between:\n",
    "                    group.at[view_index, 'already_in_cart'] = 1\n",
    "                break  # Only mark the first view after the cart\n",
    "\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of user_id and product_id\n",
    "df = df.groupby(['user_id', 'product_id']).apply(mark_view_after_cart)\n",
    "\n",
    "\n",
    "# Overwrite our final file\n",
    "df.to_csv('../data/events_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>last_view_before_purchase</th>\n",
       "      <th>last_view_before_cart</th>\n",
       "      <th>already_in_cart</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515915625353226922</th>\n",
       "      <th>4101974</th>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-29 11:28:35+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>4101974</td>\n",
       "      <td>2144415939364389423</td>\n",
       "      <td>electronics.clocks</td>\n",
       "      <td>honor</td>\n",
       "      <td>76.48</td>\n",
       "      <td>1515915625353226922</td>\n",
       "      <td>7qejzWzHlR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515915625353230067</th>\n",
       "      <th>3506650</th>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-06 06:30:32+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>3506650</td>\n",
       "      <td>2144415935673401802</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>kester</td>\n",
       "      <td>28.98</td>\n",
       "      <td>1515915625353230067</td>\n",
       "      <td>ikPKHkuRhA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1515915625353230683</th>\n",
       "      <th>124883</th>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-09 08:52:51+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>124883</td>\n",
       "      <td>2144415924424278172</td>\n",
       "      <td>electronics.audio.acoustic</td>\n",
       "      <td>logitech</td>\n",
       "      <td>23.90</td>\n",
       "      <td>1515915625353230683</td>\n",
       "      <td>dn9FkZ11dA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125325</th>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-09 09:08:53+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>125325</td>\n",
       "      <td>2144415924424278172</td>\n",
       "      <td>electronics.audio.acoustic</td>\n",
       "      <td>logitech</td>\n",
       "      <td>23.90</td>\n",
       "      <td>1515915625353230683</td>\n",
       "      <td>dn9FkZ11dA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254763</th>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-18 10:51:35+00:00</td>\n",
       "      <td>view</td>\n",
       "      <td>254763</td>\n",
       "      <td>2144415924424278172</td>\n",
       "      <td>electronics.audio.acoustic</td>\n",
       "      <td>creative</td>\n",
       "      <td>74.24</td>\n",
       "      <td>1515915625353230683</td>\n",
       "      <td>5qXvZIBV2W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                event_time event_type  \\\n",
       "user_id             product_id                                          \n",
       "1515915625353226922 4101974    0 2020-10-29 11:28:35+00:00       view   \n",
       "1515915625353230067 3506650    1 2020-10-06 06:30:32+00:00       view   \n",
       "1515915625353230683 124883     2 2020-11-09 08:52:51+00:00       view   \n",
       "                    125325     3 2020-11-09 09:08:53+00:00       view   \n",
       "                    254763     4 2020-11-18 10:51:35+00:00       view   \n",
       "\n",
       "                                  product_id          category_id  \\\n",
       "user_id             product_id                                      \n",
       "1515915625353226922 4101974    0     4101974  2144415939364389423   \n",
       "1515915625353230067 3506650    1     3506650  2144415935673401802   \n",
       "1515915625353230683 124883     2      124883  2144415924424278172   \n",
       "                    125325     3      125325  2144415924424278172   \n",
       "                    254763     4      254763  2144415924424278172   \n",
       "\n",
       "                                               category_code     brand  price  \\\n",
       "user_id             product_id                                                  \n",
       "1515915625353226922 4101974    0          electronics.clocks     honor  76.48   \n",
       "1515915625353230067 3506650    1                     Unknown    kester  28.98   \n",
       "1515915625353230683 124883     2  electronics.audio.acoustic  logitech  23.90   \n",
       "                    125325     3  electronics.audio.acoustic  logitech  23.90   \n",
       "                    254763     4  electronics.audio.acoustic  creative  74.24   \n",
       "\n",
       "                                              user_id user_session  \\\n",
       "user_id             product_id                                       \n",
       "1515915625353226922 4101974    0  1515915625353226922   7qejzWzHlR   \n",
       "1515915625353230067 3506650    1  1515915625353230067   ikPKHkuRhA   \n",
       "1515915625353230683 124883     2  1515915625353230683   dn9FkZ11dA   \n",
       "                    125325     3  1515915625353230683   dn9FkZ11dA   \n",
       "                    254763     4  1515915625353230683   5qXvZIBV2W   \n",
       "\n",
       "                                  last_view_before_purchase  \\\n",
       "user_id             product_id                                \n",
       "1515915625353226922 4101974    0                          0   \n",
       "1515915625353230067 3506650    1                          0   \n",
       "1515915625353230683 124883     2                          0   \n",
       "                    125325     3                          0   \n",
       "                    254763     4                          0   \n",
       "\n",
       "                                  last_view_before_cart  already_in_cart  \n",
       "user_id             product_id                                            \n",
       "1515915625353226922 4101974    0                      0                0  \n",
       "1515915625353230067 3506650    1                      0                0  \n",
       "1515915625353230683 124883     2                      0                0  \n",
       "                    125325     3                      0                0  \n",
       "                    254763     4                      0                0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
